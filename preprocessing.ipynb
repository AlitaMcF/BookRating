{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bookID', 'title', 'author', 'average_rating', 'isbn', 'isbn13',\n",
      "       'language_code', 'num_pages', 'ratings_count', 'text_reviews_count',\n",
      "       'publication_date', 'publisher'],\n",
      "      dtype='object')\n",
      "Index(['bookID', 'title', 'authors', 'average_rating', 'isbn', 'isbn13',\n",
      "       'language_code', '  num_pages', 'ratings_count', 'text_reviews_count',\n",
      "       'publication_date', 'publisher'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('raw_data/Train_data_2.csv')\n",
    "test = pd.read_csv('raw_data/Test_data_2.csv')\n",
    "train_header = train.columns\n",
    "test_header = test.columns\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "print(train_header)\n",
    "print(test_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_element:\n",
      " ['ara' 'en-CA' 'en-GB' 'en-US' 'eng' 'enm' 'fre' 'ger' 'gla' 'glg' 'grc'\n",
      " 'ita' 'jpn' 'lat' 'msa' 'mul' 'nl' 'nor' 'por' 'rus' 'spa' 'srp' 'swe'\n",
      " 'tur' 'wel' 'zho'] \n",
      "\n",
      "lang_count:\n",
      " {'ara': 1, 'en-CA': 6, 'en-GB': 186, 'en-US': 1274, 'eng': 7913, 'enm': 3, 'fre': 125, 'ger': 82, 'gla': 1, 'glg': 1, 'grc': 9, 'ita': 4, 'jpn': 43, 'lat': 3, 'msa': 1, 'mul': 19, 'nl': 1, 'nor': 1, 'por': 9, 'rus': 2, 'spa': 181, 'srp': 1, 'swe': 2, 'tur': 1, 'wel': 1, 'zho': 12} \n",
      "\n",
      "lang_avg_rating:\n",
      " [3.55 4.03 3.93 3.92 3.94 3.87 3.98 3.94 4.47 3.36 3.47 4.1  4.27 4.35\n",
      " 4.11 4.13 4.18 3.6  3.96 4.26 3.94 0.   3.46 4.42 5.   4.53] \n",
      "\n",
      "total_avg_rating:\n",
      " 3.88 \n",
      "\n",
      "bayesian_avg_lang_rating:\n",
      " [3.82 3.96 3.93 3.92 3.94 3.88 3.98 3.94 3.98 3.79 3.62 3.98 4.23 4.06\n",
      " 3.92 4.08 3.93 3.83 3.93 3.99 3.94 3.23 3.76 3.97 4.07 4.34] \n",
      "\n",
      "unique_element_test:\n",
      " ['ale' 'en-CA' 'en-GB' 'en-US' 'eng' 'fre' 'ger' 'grc' 'ita' 'jpn' 'por'\n",
      " 'spa' 'zho'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# processing language feature\n",
    "lang = train[:, 6]\n",
    "unique_element = np.unique(lang)\n",
    "print('unique_element:\\n', unique_element, '\\n')\n",
    "\n",
    "lang_count = Counter(lang)\n",
    "lang_count = dict(lang_count)\n",
    "lang_count = sorted(lang_count.items())\n",
    "lang_count = dict(lang_count)\n",
    "print('lang_count:\\n', lang_count, '\\n')\n",
    "\n",
    "lang_avg_rating = []\n",
    "for i in range(len(unique_element)):\n",
    "    lang_avg_rating.append(np.mean([train[j, 3] for j in range(len(lang)) if lang[j] == unique_element[i]]))\n",
    "lang_avg_rating = np.around(lang_avg_rating, 2)\n",
    "print('lang_avg_rating:\\n', lang_avg_rating, '\\n')\n",
    "total_avg_rating = np.mean(lang_avg_rating)\n",
    "total_avg_rating = np.around(total_avg_rating, 2)\n",
    "print('total_avg_rating:\\n', total_avg_rating, '\\n')\n",
    "\n",
    "# use Bayesian average\n",
    "bayesian_avg_lang_rating = []\n",
    "for i in range(len(unique_element)):\n",
    "    element_num = lang_count[unique_element[i]]\n",
    "    bayesian_avg_lang_rating.append(5/(5+element_num)*total_avg_rating + (element_num/(element_num+5))*lang_avg_rating[i])\n",
    "bayesian_avg_lang_rating = np.around(bayesian_avg_lang_rating, 2)\n",
    "print('bayesian_avg_lang_rating:\\n', bayesian_avg_lang_rating, '\\n')\n",
    "\n",
    "# replace all language feature of trainset and testset\n",
    "for i in range(len(unique_element)):\n",
    "    for j in range(len(lang)):\n",
    "        if lang[j] == unique_element[i]:\n",
    "            lang[j] = bayesian_avg_lang_rating[i]\n",
    "train[:, 6] = lang\n",
    "\n",
    "# replace test set language\n",
    "lang_test = test[:, 6]\n",
    "unique_element_test = np.unique(lang_test)\n",
    "print('unique_element_test:\\n', unique_element_test, '\\n')\n",
    "\n",
    "for i in range(len(unique_element_test)):\n",
    "    for j in range(len(lang_test)):\n",
    "        if lang_test[j] == unique_element[i]:\n",
    "            lang_test[j] = bayesian_avg_lang_rating[i]\n",
    "for j in range(len(lang_test)):\n",
    "    if isinstance(lang_test[j], str):\n",
    "        lang_test[j] = total_avg_rating\n",
    "\n",
    "test[:, 6] = lang_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_nation:\n",
      " ['Argentina' 'Brazil' 'Colombia' 'Egypt' 'English language'\n",
      " 'French language' 'German language' 'Hong Kong, China' 'India'\n",
      " 'Indonesia' 'Italy' 'Japan' 'Malaysia' 'Mexico' 'Netherlands' 'Portugal'\n",
      " 'Singapore' 'Spain' 'Sweden' 'Taiwan' 'former U.S.S.R'\n",
      " 'former Yugoslavia'] \n",
      "\n",
      "nation_count:\n",
      " {'Argentina': 11, 'Brazil': 3, 'Colombia': 4, 'Egypt': 1, 'English language': 9455, 'French language': 118, 'German language': 93, 'Hong Kong, China': 2, 'India': 1, 'Indonesia': 1, 'Italy': 3, 'Japan': 50, 'Malaysia': 1, 'Mexico': 11, 'Netherlands': 3, 'Portugal': 6, 'Singapore': 2, 'Spain': 100, 'Sweden': 1, 'Taiwan': 12, 'former U.S.S.R': 3, 'former Yugoslavia': 1} \n",
      "\n",
      "nation_avg_rating:\n",
      " [4.08 3.89 3.96 3.55 3.93 3.98 3.91 3.56 4.23 3.44 4.13 4.17 4.11 3.89\n",
      " 2.63 4.   3.85 3.91 3.   4.53 4.08 0.  ] \n",
      "\n",
      "total_avg_rating:\n",
      " 3.67 \n",
      "\n",
      "bayesian_avg_nation_rating:\n",
      " [3.95 3.75 3.8  3.65 3.93 3.97 3.9  3.64 3.76 3.63 3.84 4.12 3.74 3.82\n",
      " 3.28 3.85 3.72 3.9  3.56 4.28 3.82 3.06] \n",
      "\n",
      "unique_element_test:\n",
      " ['Brazil' 'English language' 'French language' 'German language'\n",
      " 'Hong Kong, China' 'Italy' 'Japan' 'Spain' 'Taiwan'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# processing nation feature\n",
    "nations = train[:, 5]\n",
    "unique_nation = np.unique(nations)\n",
    "print('unique_nation:\\n', unique_nation, '\\n')\n",
    "\n",
    "nation_count = Counter(nations)\n",
    "nation_count = dict(nation_count)\n",
    "nation_count = sorted(nation_count.items())\n",
    "nation_count = dict(nation_count)\n",
    "print('nation_count:\\n', nation_count, '\\n')\n",
    "\n",
    "nation_avg_rating = []\n",
    "for i in range(len(unique_nation)):\n",
    "    nation_avg_rating.append(np.mean([train[j, 3] for j in range(len(nations)) if nations[j] == unique_nation[i]]))\n",
    "nation_avg_rating = np.around(nation_avg_rating, 2)\n",
    "print('nation_avg_rating:\\n', nation_avg_rating, '\\n')\n",
    "total_avg_rating = np.mean(nation_avg_rating)\n",
    "total_avg_rating = np.around(total_avg_rating, 2)\n",
    "print('total_avg_rating:\\n', total_avg_rating, '\\n')\n",
    "\n",
    "# use Bayesian average\n",
    "bayesian_avg_nation_rating = []\n",
    "for i in range(len(unique_nation)):\n",
    "    element_num = nation_count[unique_nation[i]]\n",
    "    bayesian_avg_nation_rating.append(5/(5+element_num)*total_avg_rating+(element_num/(element_num+5))*nation_avg_rating[i])\n",
    "bayesian_avg_nation_rating = np.around(bayesian_avg_nation_rating, 2)\n",
    "print('bayesian_avg_nation_rating:\\n', bayesian_avg_nation_rating, '\\n')\n",
    "\n",
    "# replace all nation feature of trainset and testset\n",
    "for i in range(len(unique_nation)):\n",
    "    for j in range(len(nations)):\n",
    "        if nations[j] == unique_nation[i]:\n",
    "            nations[j] = bayesian_avg_nation_rating[i]\n",
    "train[:, 5] = nations\n",
    "\n",
    "# replace test set nation\n",
    "nation_test = test[:, 5]\n",
    "unique_element_test = np.unique(nation_test)\n",
    "print('unique_element_test:\\n', unique_element_test, '\\n')\n",
    "\n",
    "for i in range(len(unique_element_test)):\n",
    "    for j in range(len(nation_test)):\n",
    "        if nation_test[j] == unique_nation[i]:\n",
    "            nation_test[j] = bayesian_avg_nation_rating[i]\n",
    "for j in range(len(nation_test)):\n",
    "    if isinstance(nation_test[j], str):\n",
    "        nation_test[j] = total_avg_rating\n",
    "test[:, 5] = nation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author total num: 8442 \n",
      "\n",
      "total_avg_author_rating: 3.92 \n",
      "\n",
      "bayesian_avg_author_rating: [4.03 3.95 3.92 ... 4.04 4.43 4.14] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessing author feature\n",
    "author_train = train[:, 2]\n",
    "author_all = []\n",
    "author_unique = []\n",
    "for i in range(len(author_train)):\n",
    "    authors = author_train[i].split('/')\n",
    "    for j in range(len(authors)):\n",
    "        author_all.append(authors[j])\n",
    "author_unique = list(set(author_all))\n",
    "author_unique = sorted(author_unique)\n",
    "print('author total num:', len(author_unique), '\\n')\n",
    "\n",
    "# count author num\n",
    "author_num = Counter(author_all)\n",
    "author_num = dict(author_num)\n",
    "author_num = sorted(author_num.items())\n",
    "author_num = dict(author_num)\n",
    "\n",
    "# count author rating\n",
    "author_rating = []\n",
    "for i in range(len(author_unique)):\n",
    "    author_rating.append(np.mean([train[j, 3] for j in range(len(author_train)) if author_unique[i] in author_train[j]]))\n",
    "\n",
    "# count total average rating of author\n",
    "total_avg_author_rating = np.mean(author_rating)\n",
    "total_avg_author_rating = np.around(total_avg_author_rating, 2)\n",
    "print('total_avg_author_rating:', total_avg_author_rating, '\\n')\n",
    "\n",
    "# count author bayesian average rating\n",
    "bayesian_avg_author_rating = []\n",
    "for i in range(len(author_unique)):\n",
    "    element_num = author_num[author_unique[i]]\n",
    "    bayesian_avg_author_rating.append(element_num/(element_num+2)*author_rating[i] + 2/(element_num+2)*total_avg_author_rating)\n",
    "bayesian_avg_author_rating = np.around(bayesian_avg_author_rating, 2)\n",
    "print('bayesian_avg_author_rating:', bayesian_avg_author_rating, '\\n')\n",
    "\n",
    "# replace train set author feature\n",
    "for i in range(len(author_train)):\n",
    "    authors = author_train[i].split('/')\n",
    "    score = 0\n",
    "    for j in range(len(authors)):\n",
    "        score += bayesian_avg_author_rating[author_unique.index(authors[j])]\n",
    "    author_train[i] = score/len(authors)\n",
    "author_train = np.around(np.float64(author_train), 2)\n",
    "train[:, 2] = author_train\n",
    "\n",
    "# replace test set author feature\n",
    "author_test = test[:, 2]\n",
    "for i in range(len(author_test)):\n",
    "    authors = author_test[i].split('/')\n",
    "    score = []\n",
    "    for j in range(len(authors)):\n",
    "        if authors[j] in author_unique:\n",
    "            score.append(bayesian_avg_author_rating[author_unique.index(authors[j])])\n",
    "        else:\n",
    "            score.append(total_avg_author_rating)\n",
    "    author_test[i] = np.mean(score)\n",
    "author_test = np.around(np.float64(author_test), 2)\n",
    "test[:, 2] = author_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher total num: 2130 \n",
      "\n",
      "total_avg_publisher_rating: 3.92 \n",
      "\n",
      "bayesian_avg_publisher_rating: [3.84 3.81 4.01 ... 3.87 4.19 4.19] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessing publisher feature\n",
    "publisher_train = train[:, 11]\n",
    "publisher_all = []\n",
    "publisher_unique = []\n",
    "for i in range(len(publisher_train)):\n",
    "    publisher_all.append(publisher_train[i])\n",
    "publisher_unique = list(set(publisher_all))\n",
    "publisher_unique = sorted(publisher_unique)\n",
    "print('publisher total num:', len(publisher_unique), '\\n')\n",
    "\n",
    "# count publisher num\n",
    "publisher_num = Counter(publisher_all)\n",
    "publisher_num = dict(publisher_num)\n",
    "publisher_num = sorted(publisher_num.items())\n",
    "publisher_num = dict(publisher_num)\n",
    "\n",
    "# count publisher rating\n",
    "publisher_rating = []\n",
    "for i in range(len(publisher_unique)):\n",
    "    publisher_rating.append(np.mean([train[j,3] for j in range(len(publisher_train)) if publisher_unique[i] in publisher_train[j]]))\n",
    "\n",
    "# count total average rating of publisher\n",
    "total_avg_publisher_rating = np.mean(publisher_rating)\n",
    "total_avg_publisher_rating = np.around(total_avg_publisher_rating, 2)\n",
    "print('total_avg_publisher_rating:', total_avg_publisher_rating, '\\n')\n",
    "\n",
    "# count publisher bayesian average rating\n",
    "bayesian_avg_publisher_rating = []\n",
    "for i in range(len(publisher_unique)):\n",
    "    element_num = publisher_num[publisher_unique[i]]\n",
    "    bayesian_avg_publisher_rating.append(element_num/(element_num+2)*publisher_rating[i] + 2/(element_num+2)*total_avg_publisher_rating)\n",
    "bayesian_avg_publisher_rating = np.around(bayesian_avg_publisher_rating, 2)\n",
    "print('bayesian_avg_publisher_rating:', bayesian_avg_publisher_rating, '\\n')\n",
    "\n",
    "# replace train set publisher feature\n",
    "for i in range(len(publisher_train)):\n",
    "    publisher_train[i] = bayesian_avg_publisher_rating[publisher_unique.index(publisher_train[i])]\n",
    "publisher_train = np.around(np.float64(publisher_train), 2)\n",
    "train[:, 11] = publisher_train\n",
    "\n",
    "# replace test set publisher feature\n",
    "publisher_test = test[:, 11]\n",
    "for i in range(len(publisher_test)):\n",
    "    if publisher_test[i] in publisher_unique:\n",
    "        publisher_test[i] = bayesian_avg_publisher_rating[publisher_unique.index(publisher_test[i])]\n",
    "    else:\n",
    "        publisher_test[i] = total_avg_publisher_rating\n",
    "publisher_test = np.around(np.float64(publisher_test), 2)\n",
    "test[:, 11] = publisher_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess test_data datetime\n",
    "\n",
    "date = test[:, -2]\n",
    "for i in range(len(date)):\n",
    "    date[i] = date[i].split(\"/\")[0]\n",
    "test[:, -2] = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write to file\n",
    "train = pd.DataFrame(train)\n",
    "train.to_csv('./processed_data/train_processed_language_author.csv', header=train_header)\n",
    "\n",
    "test = pd.DataFrame(test)\n",
    "test.to_csv('./processed_data/test_processed_language_author.csv', header=test_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write to file\n",
    "train = pd.DataFrame(train)\n",
    "train.to_csv('./processed_data/train_processed_language_author_publisher_nation.csv', header=train_header, index=None)\n",
    "\n",
    "test = pd.DataFrame(test)\n",
    "test.to_csv('./processed_data/test_processed_language_author_publisher_nation.csv', header=test_header, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 舍弃isbn，因为提取出来的info与language重合了\n",
    "# isbn = train[:, 4]\n",
    "# delete_index = []\n",
    "# for i in range(len(isbn)):\n",
    "#     isbn[i] = isbnlib.to_isbn10(str(isbn[i]))\n",
    "#     if isbn[i] == '':\n",
    "#         delete_index.append(i)\n",
    "# isbn = [isbn[i] for i in range(len(isbn)) if i not in delete_index]\n",
    "# print(len(isbn))\n",
    "# isbn_info = []\n",
    "# for i in range(len(isbn)):\n",
    "#     isbn_info.append(isbnlib.info(isbn[i]))\n",
    "#     print(isbn_info[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
