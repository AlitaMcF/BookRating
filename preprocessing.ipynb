{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bookID', 'title', 'authors', 'average_rating', 'isbn', 'isbn13',\n",
      "       'language_code', '  num_pages', 'ratings_count', 'text_reviews_count',\n",
      "       'publication_date', 'publisher'],\n",
      "      dtype='object')\n",
      "Index(['bookID', 'title', 'authors', 'average_rating', 'isbn', 'isbn13',\n",
      "       'language_code', '  num_pages', 'ratings_count', 'text_reviews_count',\n",
      "       'publication_date', 'publisher'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('raw_data/Train_data.csv')\n",
    "test = pd.read_csv('raw_data/Test_data.csv')\n",
    "train_header = train.columns\n",
    "test_header = test.columns\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "print(train_header)\n",
    "print(test_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_element:\n",
      " ['ara' 'en-CA' 'en-GB' 'en-US' 'eng' 'enm' 'fre' 'ger' 'gla' 'glg' 'grc'\n",
      " 'ita' 'jpn' 'lat' 'msa' 'mul' 'nl' 'nor' 'por' 'rus' 'spa' 'srp' 'swe'\n",
      " 'tur' 'wel' 'zho'] \n",
      "\n",
      "lang_count:\n",
      " {'ara': 1, 'en-CA': 6, 'en-GB': 189, 'en-US': 1285, 'eng': 8001, 'enm': 3, 'fre': 130, 'ger': 85, 'gla': 1, 'glg': 1, 'grc': 10, 'ita': 4, 'jpn': 44, 'lat': 3, 'msa': 1, 'mul': 19, 'nl': 1, 'nor': 1, 'por': 9, 'rus': 2, 'spa': 187, 'srp': 1, 'swe': 2, 'tur': 1, 'wel': 1, 'zho': 12} \n",
      "\n",
      "lang_avg_rating:\n",
      " [3.55 4.03 3.93 3.92 3.93 3.87 3.98 3.95 4.47 3.36 3.62 4.1  4.27 4.35\n",
      " 4.11 4.13 4.18 3.6  3.96 4.26 3.95 0.   3.46 4.42 5.   4.53] \n",
      "\n",
      "total_avg_rating:\n",
      " 3.88 \n",
      "\n",
      "bayesian_avg_lang_rating:\n",
      " [3.82 3.96 3.93 3.92 3.93 3.88 3.98 3.95 3.98 3.79 3.71 3.98 4.23 4.06\n",
      " 3.92 4.08 3.93 3.83 3.93 3.99 3.95 3.23 3.76 3.97 4.07 4.34] \n",
      "\n",
      "unique_element_test:\n",
      " ['ale' 'en-CA' 'en-GB' 'en-US' 'eng' 'fre' 'ger' 'grc' 'ita' 'jpn' 'por'\n",
      " 'spa' 'zho'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# processing language feature\n",
    "lang = train[:, 6]\n",
    "unique_element = np.unique(lang)\n",
    "print('unique_element:\\n', unique_element, '\\n')\n",
    "\n",
    "lang_count = Counter(lang)\n",
    "lang_count = dict(lang_count)\n",
    "lang_count = sorted(lang_count.items())\n",
    "lang_count = dict(lang_count)\n",
    "print('lang_count:\\n', lang_count, '\\n')\n",
    "\n",
    "lang_avg_rating = []\n",
    "for i in range(len(unique_element)):\n",
    "    lang_avg_rating.append(np.mean([train[j, 3] for j in range(len(lang)) if lang[j] == unique_element[i]]))\n",
    "lang_avg_rating = np.around(lang_avg_rating, 2)\n",
    "print('lang_avg_rating:\\n', lang_avg_rating, '\\n')\n",
    "total_avg_rating = np.mean(lang_avg_rating)\n",
    "total_avg_rating = np.around(total_avg_rating, 2)\n",
    "print('total_avg_rating:\\n', total_avg_rating, '\\n')\n",
    "\n",
    "# use Bayesian average\n",
    "bayesian_avg_lang_rating = []\n",
    "for i in range(len(unique_element)):\n",
    "    element_num = lang_count[unique_element[i]]\n",
    "    bayesian_avg_lang_rating.append(5/(5+element_num)*total_avg_rating + (element_num/(element_num+5))*lang_avg_rating[i])\n",
    "bayesian_avg_lang_rating = np.around(bayesian_avg_lang_rating, 2)\n",
    "print('bayesian_avg_lang_rating:\\n', bayesian_avg_lang_rating, '\\n')\n",
    "\n",
    "# replace all language feature of trainset and testset\n",
    "for i in range(len(unique_element)):\n",
    "    for j in range(len(lang)):\n",
    "        if lang[j] == unique_element[i]:\n",
    "            lang[j] = bayesian_avg_lang_rating[i]\n",
    "train[:, 6] = lang\n",
    "\n",
    "# replace test set language\n",
    "lang_test = test[:, 6]\n",
    "unique_element_test = np.unique(lang_test)\n",
    "print('unique_element_test:\\n', unique_element_test, '\\n')\n",
    "\n",
    "for i in range(len(unique_element_test)):\n",
    "    for j in range(len(lang_test)):\n",
    "        if lang_test[j] == unique_element[i]:\n",
    "            lang_test[j] = bayesian_avg_lang_rating[i]\n",
    "for j in range(len(lang_test)):\n",
    "    if isinstance(lang_test[j], str):\n",
    "        lang_test[j] = total_avg_rating\n",
    "\n",
    "test[:, 6] = lang_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author total num: 8535 \n",
      "\n",
      "total_avg_author_rating: 3.92 \n",
      "\n",
      "bayesian_avg_author_rating: [4.03 3.95 3.92 ... 4.04 4.43 4.14] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessing author feature\n",
    "author_train = train[:, 2]\n",
    "author_all = []\n",
    "author_unique = []\n",
    "for i in range(len(author_train)):\n",
    "    authors = author_train[i].split('/')\n",
    "    for j in range(len(authors)):\n",
    "        author_all.append(authors[j])\n",
    "author_unique = list(set(author_all))\n",
    "author_unique = sorted(author_unique)\n",
    "print('author total num:', len(author_unique), '\\n')\n",
    "\n",
    "# count author num\n",
    "author_num = Counter(author_all)\n",
    "author_num = dict(author_num)\n",
    "author_num = sorted(author_num.items())\n",
    "author_num = dict(author_num)\n",
    "\n",
    "# count author rating\n",
    "author_rating = []\n",
    "for i in range(len(author_unique)):\n",
    "    author_rating.append(np.mean([train[j, 3] for j in range(len(author_train)) if author_unique[i] in author_train[j]]))\n",
    "\n",
    "# count total average rating of author\n",
    "total_avg_author_rating = np.mean(author_rating)\n",
    "total_avg_author_rating = np.around(total_avg_author_rating, 2)\n",
    "print('total_avg_author_rating:', total_avg_author_rating, '\\n')\n",
    "\n",
    "# count author bayesian average rating\n",
    "bayesian_avg_author_rating = []\n",
    "for i in range(len(author_unique)):\n",
    "    element_num = author_num[author_unique[i]]\n",
    "    bayesian_avg_author_rating.append(element_num/(element_num+2)*author_rating[i] + 2/(element_num+2)*total_avg_author_rating)\n",
    "bayesian_avg_author_rating = np.around(bayesian_avg_author_rating, 2)\n",
    "print('bayesian_avg_author_rating:', bayesian_avg_author_rating, '\\n')\n",
    "\n",
    "# replace train set author feature\n",
    "for i in range(len(author_train)):\n",
    "    authors = author_train[i].split('/')\n",
    "    score = 0\n",
    "    for j in range(len(authors)):\n",
    "        score += bayesian_avg_author_rating[author_unique.index(authors[j])]\n",
    "    author_train[i] = score/len(authors)\n",
    "author_train = np.around(np.float64(author_train), 2)\n",
    "train[:, 2] = author_train\n",
    "\n",
    "# replace test set author feature\n",
    "author_test = test[:, 2]\n",
    "for i in range(len(author_test)):\n",
    "    authors = author_test[i].split('/')\n",
    "    score = []\n",
    "    for j in range(len(authors)):\n",
    "        if authors[j] in author_unique:\n",
    "            score.append(bayesian_avg_author_rating[author_unique.index(authors[j])])\n",
    "        else:\n",
    "            score.append(total_avg_author_rating)\n",
    "    author_test[i] = np.mean(score)\n",
    "author_test = np.around(np.float64(author_test), 2)\n",
    "test[:, 2] = author_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "train = pd.DataFrame(train)\n",
    "train.to_csv('./processed_data/train_processed_language_author.csv', header=train_header)\n",
    "\n",
    "test = pd.DataFrame(test)\n",
    "test.to_csv('./processed_data/test_processed_language_author.csv', header=test_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 舍弃isbn，因为提取出来的info与language重合了\n",
    "# isbn = train[:, 4]\n",
    "# delete_index = []\n",
    "# for i in range(len(isbn)):\n",
    "#     isbn[i] = isbnlib.to_isbn10(str(isbn[i]))\n",
    "#     if isbn[i] == '':\n",
    "#         delete_index.append(i)\n",
    "# isbn = [isbn[i] for i in range(len(isbn)) if i not in delete_index]\n",
    "# print(len(isbn))\n",
    "# isbn_info = []\n",
    "# for i in range(len(isbn)):\n",
    "#     isbn_info.append(isbnlib.info(isbn[i]))\n",
    "#     print(isbn_info[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
